{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/samuramirez/cellmigration/blob/master/segmentation_1_class_cell_indiv_tiff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"8XWeD-32AStD","tags":[]},"source":["# Segmentation one class (cell)"]},{"cell_type":"markdown","metadata":{"id":"yJZxsReQegXy","tags":[]},"source":["### Mount Google Drive (Colab can see Drive files) and authenticate so that we can interact with GCP via SDK"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"U7feFl68g6fj","tags":[],"executionInfo":{"status":"ok","timestamp":1675276344970,"user_tz":300,"elapsed":305,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["try:\n","  from google.cloud import storage\n","  client = storage.Client();\n","except Exception as e:\n","  print(e)\n","  print(\"error: no credentials, ignoring\");\n","\n","try:\n","  from google.colab import auth\n","  #This allows SDK to see and edit Google Drive files\n","  #SDK is required to interact with GCP\n","  auth.authenticate_user()\n","except Exception as e:\n","  print(e);\n","  print(\"error: no colab credentials, ignoring\");\n"]},{"cell_type":"markdown","metadata":{"id":"MvFx9gc8x_t8","tags":[]},"source":["### Installing and loading packages "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-2-ceAm648s","executionInfo":{"status":"ok","timestamp":1675276366700,"user_tz":300,"elapsed":21745,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"d3c068f1-74ce-46d6-f6b7-62b523d01a56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.htmlimport\n","\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.0+cu111 (from versions: 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.0+cu111\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fastcore in /usr/local/lib/python3.8/dist-packages (1.5.27)\n","Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastcore) (22.0.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastcore) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastcore) (3.0.9)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fastai in /usr/local/lib/python3.8/dist-packages (2.7.10)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from fastai) (0.14.1+cu116)\n","Requirement already satisfied: pillow>6.0.0 in /usr/local/lib/python3.8/dist-packages (from fastai) (7.1.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from fastai) (1.0.2)\n","Requirement already satisfied: torch<1.14,>=1.7 in /usr/local/lib/python3.8/dist-packages (from fastai) (1.13.1+cu116)\n","Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from fastai) (22.0.4)\n","Requirement already satisfied: fastcore<1.6,>=1.4.5 in /usr/local/lib/python3.8/dist-packages (from fastai) (1.5.27)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from fastai) (1.7.3)\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from fastai) (0.0.7)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from fastai) (3.2.2)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.8/dist-packages (from fastai) (3.4.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from fastai) (21.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from fastai) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fastai) (2.25.1)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.8/dist-packages (from fastai) (1.0.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fastai) (1.3.5)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (1.0.4)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (2.0.8)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (3.3.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (2.0.7)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (4.64.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (0.10.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (1.10.4)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (3.0.8)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (0.10.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (1.21.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (2.11.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (6.3.0)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (8.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (57.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (3.0.11)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (1.0.9)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (0.7.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4->fastai) (2.4.5)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->fastai) (3.0.9)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fastai) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fastai) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fastai) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fastai) (2022.12.7)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<1.14,>=1.7->fastai) (4.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->fastai) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->fastai) (2022.7)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->fastai) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->fastai) (1.15.0)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4->fastai) (0.0.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<4->fastai) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4->fastai) (2.0.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: imagecodecs in /usr/local/lib/python3.8/dist-packages (2023.1.23)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imagecodecs) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.10.10)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.9.0)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.21.6)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.7.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n"]}],"source":["#Install packages (skippable for speed)\n","!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.htmlimport torch\n","!pip install fastcore --upgrade\n","!pip install fastai --upgrade\n","!pip install imagecodecs --upgrade\n","!pip install scikit-image --upgrade"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"TClA_sMuQ6dV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675276367576,"user_tz":300,"elapsed":892,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"d88f280a-1cca-40fe-993f-48ba71ff9233"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Feb  1 18:32:47 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    23W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["#Check for cuda\n","!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"prkUN4o0Q6dX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675276369755,"user_tz":300,"elapsed":2189,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"f55a5689-e253-470f-c5b8-de66ad926abf"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n","  from .collection import imread_collection_wrapper\n"]}],"source":["import torch\n","import torchvision\n","import fastai\n","from fastai.vision.all import *\n","from skimage.io import imread, imsave, imshow\n","from skimage.exposure import rescale_intensity\n","import os\n","import numpy as np\n","from pathlib import Path\n","import re\n","import ntpath\n","from datetime import datetime\n","from fastprogress.core import format_time\n","from IPython.utils.io import capture_output\n","import logging"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WscEEK3JQ6df","outputId":"8ae9783d-2df3-4488-ae90-f18fce5c9f7e","executionInfo":{"status":"ok","timestamp":1675276370783,"user_tz":300,"elapsed":231,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda available: True\n"]}],"source":["print(\"cuda available:\", torch.cuda.is_available());"]},{"cell_type":"markdown","metadata":{"id":"0XW_ZhfmdoFd","tags":[]},"source":["# Segmentation Parameters\n"]},{"cell_type":"markdown","metadata":{"id":"7hY-e7sBevDA","tags":[]},"source":["## Basic Parameters\n","other shared settings between training and separation"]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"id":"mFZ18qWWd7wu","outputId":"a9a3172b-8d04-4b45-9e9c-33f2cab1fa9b","executionInfo":{"status":"ok","timestamp":1675276370785,"user_tz":300,"elapsed":40,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["activating process logging\n"]}],"source":["#@markdown What object type you are segmenting\n","segmentation_target = \"Separate - Cell + Nucleus models (two output folders)\" #@param [\"Nucleus\", \"Cell\", \"Separate - Cell + Nucleus models (two output folders)\", \"Combined - Cell + Nucleus models\", \"Separate - Single Model (two output folders)\", \"Combined - Single Model\",\"Custom Models\"]\n","\n","\n","#@markdown local folder where all images and masks to be transferred to and from the GCP will be stored\n","GCP_transfer_folder = \"gcp_transfer\" #@param {type:\"string\"}\n","GCP_transfer_folder = Path(GCP_transfer_folder);\n","if not os.path.exists(GCP_transfer_folder):\n","  os.makedirs(GCP_transfer_folder);\n","\n","gsutil_dest_folder = GCP_transfer_folder;\n","\n","#@markdown regex used to decipher filenames (Leave the same for metamorph outputs)\n","filename_regex = \"p[0-9]*_s([0-9]+)_t([0-9]+).*\\\\.(tif|tiff|TIF|TIFF)\" #@param {type:\"string\"}\n","\n","#@markdown whether the notebook is being run in a location with persistent file storage (local or GCE VM), as opposed to something like google colab. Will be set to False automatically if google colab is detected.\n","persistent_files = True #@param {type:\"boolean\"}\n","try:\n","    from colab import drive\n","    persistent_files = False;\n","except Exception:\n","    pass;\n","\n","#@markdown will put checkpoint outputs into a log folder logs/\n","process_logging = True #@param {type:\"boolean\"}\n","if process_logging:\n","    print(\"activating process logging\");\n","    import logging\n","    log_folder = Path(\"logs\");\n","    if not os.path.exists(log_folder): os.mkdir(log_folder);\n","    foldername = \"log_\" + str(datetime.now()) + \".txt\";\n","    log_filepath = log_folder/foldername;\n","    logging.basicConfig(filename=log_filepath, level=logging.DEBUG,force=True);\n","    # del log_folder;"]},{"cell_type":"markdown","metadata":{"id":"iwz4e8sShMW0","tags":[]},"source":["## Cloud Storage Parameters\n","Filenames and parameters for using google cloud storage"]},{"cell_type":"code","execution_count":7,"metadata":{"cellView":"form","id":"3mmU7h23hUW4","executionInfo":{"status":"ok","timestamp":1675276370786,"user_tz":300,"elapsed":37,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["#@markdown The name of the bucket to use (exclude the gs://)\n","bucket = Path(\"optotaxisbucket\") #@param {type:\"string\"}\n","\n","# #@markdown the name of the high level directory in the bucket to which movie segmentation files wil be uploaded\n","# GCP_parent_dir = \"movie_segmentation\" #@param {type:\"string\"}\n","# GCP_parent_dir = Path(bucket)/GCP_parent_dir\n","# #NOTE: whenever gsutil is used with GCP_parent_dir, you must add gs://{directory}\n","\n","#@markdown the path to the folder in the bucket (exclude the bucket name) where models are stored and will be exported to after training\n","modelsfolder = 'models/fastai' #@param {type:\"string\"}\n","gcp_modelsfolder = bucket/modelsfolder;\n","local_modelsfolder = GCP_transfer_folder/os.path.basename(modelsfolder);\n","del modelsfolder; #for testing purposes to make sure no old code is using this"]},{"cell_type":"markdown","metadata":{"id":"fhr4J0p_fJnl","tags":[]},"source":["## Image Preparation\n","shared settings between training and segmentation image/mask processing"]},{"cell_type":"code","execution_count":8,"metadata":{"cellView":"form","id":"a50wUZ5cfRMn","executionInfo":{"status":"ok","timestamp":1675276370788,"user_tz":300,"elapsed":36,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["#@markdown Number of slices (columns/rows) to divide input images into; for the math, pleast check https://www.desmos.com/calculator/t3cyflvlef\n","x_slices = 5 #@param {type:\"integer\"}\n","y_slices =  5 #@param {type:\"integer\"}\n","#@markdown dx, dy are the extra context around the segmented center in both directions\n","dx =  42#@param {type:\"integer\"}\n","dy =  32#@param {type:\"integer\"}\n","#@markdown x and y crop are how much to straight remove from the image to make the sizes able to be subdivided nicely\n","x_crop = 0 #@param {type:\"integer\"}\n","y_crop = 0 #@param {type:\"integer\"}\n","\n","context_bounds = [dy,dx]*2 #assuming x and y symmetrical, not always true -- fix?\n","crop = [y_crop,x_crop]*2 #both of these are negative y, negative x, positive y, positive x\n","\n","#@markdown whether to rescale images to their minimum and maximum pixel values; not used if external processing\n","auto_rescale = True; #@param {type:\"bool\"}"]},{"cell_type":"markdown","metadata":{"id":"LwGWGb_ggkKQ","tags":[]},"source":["## Training-Specific Settings\n","parameters and paths only for training"]},{"cell_type":"code","execution_count":9,"metadata":{"cellView":"form","id":"tQoLvKCmeENX","executionInfo":{"status":"ok","timestamp":1675276370790,"user_tz":300,"elapsed":37,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["#@markdown path to the input images within the GCP bucket (exclude the bucket name)\n","training_images=\"training_images\" #@param {type:\"string\"}\n","gcp_training_images=bucket/training_images;\n","local_training_images = GCP_transfer_folder/training_images;\n","del training_images; #for testing purposes to make sure no old code is using this\n","\n","#@markdown path to the input masks within the GCP bucket (exclude the bucket name)\n","training_masks=\"/content/gdrive/Othercomputers/My PC/segmentation_iteration_testing/processing/training_masks\" #@param {type:\"string\"}\n","gcp_training_masks=bucket/training_masks\n","local_training_masks = GCP_transfer_folder/training_masks;\n","del training_masks; #for testing purposes to make sure no old code is using this\n","\n","#@markdown base model that will be used to train from\n","inmodelname = 'seg_nuc_062719_s_1_2_110619_bleb.pkl' #@param {type:\"string\"}\n","#@markdown where the model will be exported to after training\n","outmodelname = 'iter3_2_nuc_scratch_test.pkl' #@param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"NL8JyC0ElNRq","tags":[]},"source":["## Segmentation-Specific Settings:\n","parameters and paths only for segmenting an experiment\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"ACNpuus9lJv8","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675276370791,"user_tz":300,"elapsed":36,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"9bc91411-3b4b-4c9e-d335-8bce5168d30c"},"outputs":[{"output_type":"stream","name":"stdout","text":["out file: optotaxisbucket/movie_segmentation/2023.1.26 OptoITSN Test 41/segmentation_output_masks\n","using models: [Path('gcp_transfer/fastai/iter3_4_nuc_continue.pkl'), Path('gcp_transfer/fastai/iter1_9_continue.pkl')]\n"]}],"source":["experiment = \"2023.1.26 OptoITSN Test 41\" #@param {type: \"string\"}\n","\n","#@markdown path to the input images in the GCP bucket (exclude the bucket name)\n","segmentation_images=f\"movies/{experiment}/{experiment}\"  #@param {type:\"raw\"}\n","gcp_segmentation_images=bucket/segmentation_images;\n","local_segmentation_images = GCP_transfer_folder/Path(segmentation_images).name;\n","del segmentation_images; #for testing purposes to make sure no old code is using this\n","\n","#@markdown folder name where output masks will be deposited in the GCP bucket gcp directory. If segmentation target is \"Cell\", \"Nucleus\", or either of the \"Separate\" options, this will output to the subfolders \"Nucleus\" and \"Cell\" respectively. If target is \"Combined\", will output to the \"Combined\" subfolder\n","segmentation_output_masks=f'movie_segmentation/{experiment}/segmentation_output_masks/' #@param {type:\"raw\"}\n","gcp_segmentation_output_masks=bucket/segmentation_output_masks;\n","local_segmentation_output_masks=GCP_transfer_folder/Path(segmentation_output_masks).name;\n","del segmentation_output_masks; #for testing purposes to make sure no old code is using this\n","\n","print(\"out file:\",gcp_segmentation_output_masks)\n","\n","#@markdown whether to send output folders to (individual) zip files; if persistent_files is false, this will incur a cost of downloading any nonpersistent files from the cloud and zipping locally\n","zip_output = True; #@param {type:\"boolean\"}\n","\n","#@markdown whether splitting and stitching is already done or should be done by the program\n","external_splitting_stitching = False; #@param {type:\"boolean\"}\n","\n","#@markdown name/path in the gcp models folder to the nucleus model for segmentation. This field will not be used if segmentation target is Cell or * - Single Model\n","nucleus_model = \"iter3_4_nuc_continue.pkl\" #@param {type:\"string\"}\n","nucleus_model = local_modelsfolder/nucleus_model;\n","\n","#@markdown name/path in the gcp models folder to the cell model for segmentation. This field will not be used if segmentation target is Nucleus or * - Single Model\n","cell_model = \"iter1_9_continue.pkl\" #@param {type:\"string\"}\n","cell_model = local_modelsfolder/cell_model;\n","\n","#@markdown name/path in the gcp models folder to the combined nucleus + cell model for segmentation. This field will not be used if segmentation target is Cell, Nucleus, or Separate - Cell + Nucleus models\n","combined_model = \"\" #@param {type:\"string\"}\n","combined_model = local_modelsfolder/combined_model;\n","\n","#@markdown dict of model_name:output_folder_name items to be used if segmentation target is Custom Models. Input files will be processed once per model, and the outputs will be saved to the appropriate output file.\n","#@markdown Advanced usage: if either model_name or output_folder_name is a list/tuple, the segmentation outputs will be combined into one file or split into separate files, respectively\n","custom_models = {\"iter1_1_seg_redo.pkl\":\"Iter1\",\"iter1_2_seg_redo.pkl\":\"Iter2\",\"iter1_3_seg_redo.pkl\":\"Iter3\",\"iter1_4_seg_redo.pkl\":\"Iter4\",\"iter1_6_context_4_continue.pkl\":\"Iter6\",\"iter1_8_continue.pkl\":\"Iter8\"} #@param {type:\"raw\"}\n","relative_custom_models = {};\n","for key,val in custom_models.items():\n","    if isinstance(key,str):\n","        relative_custom_models[local_modelsfolder/key] = val;\n","    else:\n","        relative_custom_models[(local_modelsfolder/k for k in key)] = val;\n","custom_models = relative_custom_models;\n","# print(custom_models)\n","\n","used_models = {};\n","ts = [\"Nucleus\", \"Cell\", \"Separate - Cell + Nucleus models (two output folders)\", \"Combined - Cell + Nucleus models\", \"Separate - Single Model (two output folders)\", \"Combined - Single Model\",\"Custom Models\"]\n","ms = [{nucleus_model:\"Nucleus\"},{cell_model:\"Cell\"},\n","      {nucleus_model:\"Nucleus\",cell_model:\"Cell\"},\n","      {(nucleus_model,cell_model):\"Combined\"},\n","      {combined_model:(\"Nucleus\",\"Cell\")},\n","      {combined_model:\"Combined\"},\n","       custom_models]; \n","target_model_map = {x:y for x,y in zip(ts,ms)};\n","\n","\n","print(\"using models:\",list(target_model_map[segmentation_target].keys()));"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"jZC6pHLl649K"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[],"id":"TZ7BoxCG649L","executionInfo":{"status":"ok","timestamp":1675276370792,"user_tz":300,"elapsed":35,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["def get_image_files_recursively(path):\n","    path = Path(path);\n","    out = get_image_files(path);\n","    subfiles = os.listdir(path);\n","    for f in subfiles:\n","        if (os.path.isdir(f)):\n","            out += get_image_files_recursively(path/f);\n","    return out;\n","            \n","def on_rm_error( func, path, exc_info):\n","    # path contains the path of the file that couldn't be removed\n","    # let's just assume that it's read-only and unlink it.\n","    os.chmod( path, stat.S_IWRITE )\n","    # os.unlink( path )\n","\n","def cleardir(dir): #clears all files in dir without deleting dir\n","  for f in os.scandir(dir):\n","    # f = os.path.join(dir,f)\n","    if os.path.isdir(f): shutil.rmtree(f,onerror=on_rm_error); #just in case\n","    else: os.remove(f);    "]},{"cell_type":"markdown","metadata":{"id":"TM0AEKHASsWp","tags":[]},"source":["# Segment Experiment\n","Will process all images in the segmentation input folder and continuously output segmented masks into the segmentation output masks folder in GCP."]},{"cell_type":"markdown","metadata":{"id":"P9WsH51038ov","tags":[]},"source":["### Pull GCP folders to local environment"]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"0bgAJQKj649O","executionInfo":{"status":"ok","timestamp":1675276370793,"user_tz":300,"elapsed":34,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"0f8300b5-0fd0-47e6-b473-4a0e90acfda7"},"outputs":[{"output_type":"stream","name":"stdout","text":["optotaxisbucket/models/fastai\n","gcp_transfer\n"]}],"source":["print(gcp_modelsfolder)\n","print(gsutil_dest_folder)\n","if process_logging: logging.debug(\"copying remote folders...\");"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kZH_t31t38Qn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675276373797,"user_tz":300,"elapsed":3034,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"e99508a8-beb2-473f-f142-4e506005bfec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Skipping existing item: file://gcp_transfer/fastai/4x4_split_test.pkl\n","Skipping existing item: file://gcp_transfer/fastai/2x2_split_noaug_test.pkl\n","Skipping existing item: file://gcp_transfer/fastai/5x5_context_split_test.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_1_seg_redo.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_3_seg_redo.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter3_1_nuc.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter3_2_nuc_continue_test.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter3_2_nuc_scratch_test.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter3_4_nuc_continue.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_2_seg_redo.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_6_context_4_continue.pkl\n","Skipping existing item: file://gcp_transfer/fastai/seg_nuc_062719_s_1_2_110619_bleb.pkl\n","Skipping existing item: file://gcp_transfer/fastai/seg_cell_062719_s_1_2_110619_bleb.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_6_context_fromsegbleb.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_4_seg_redo.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_8_continue.pkl\n","Skipping existing item: file://gcp_transfer/fastai/iter1_9_continue.pkl\n"]}],"source":["#models folder\n","!gsutil -m cp -r -n \"gs://{gcp_modelsfolder}\" \"{gsutil_dest_folder}\"\n","# print(s)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpF6_y6X649R","executionInfo":{"status":"ok","timestamp":1675276393281,"user_tz":300,"elapsed":19491,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"86dbea8d-9086-44b9-f420-a11d99f9d143"},"outputs":[{"output_type":"stream","name":"stdout","text":["Images successfully copied\n"]}],"source":["# %%capture\n","#segmentation images\n","with capture_output() as capture:\n","    s=!gsutil -m cp -r -n \"gs://{gcp_segmentation_images}\" \"{gsutil_dest_folder}\"\n","if s[0].startswith('CommandException'):\n","    raise Exception(\"Error: unable to copy images:\\n\"+\"\\n\".join(s));\n","else:\n","    print(\"Images successfully copied\")\n","files_changed = False;\n","stitching_complete = False"]},{"cell_type":"markdown","metadata":{"id":"riJVvk80SsWw","tags":[]},"source":["### Loading a trained model"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpCLkuOpSsXA","outputId":"dd670119-f7dd-44a1-8dbc-6b71246af849","executionInfo":{"status":"ok","timestamp":1675276393486,"user_tz":300,"elapsed":212,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["available cpu count: 2\n"]}],"source":["print(\"available cpu count:\",len(os.sched_getaffinity(0)));"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BFHCBd8CSsXF","outputId":"1c49e745-8103-4ff6-fee0-8b644c7fbf33","executionInfo":{"status":"ok","timestamp":1675276395770,"user_tz":300,"elapsed":2291,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["model loaded and instructions created\n"]}],"source":["if process_logging: logging.debug(\"preparing models...\");\n","def label_func(x): return None; ##dummy function to make unpickling work, never used\n","model_outputs_dict = target_model_map[segmentation_target];\n","process_instructions = [];\n","output_dirs = [];\n","    \n","\n","\n","for model,outName in model_outputs_dict.items():\n","    key = [];\n","    if not isinstance(model,list):\n","        torchmodel=load_learner(model).model;\n","        if torch.cuda.is_available():\n","          torchmodel = torchmodel.to(\"cuda\");\n","        # torch.save(torchmodel.state_dict(),\"temp.pkl\");\n","        # torchmodel = torch.load(\"temp.pkl\");\n","        key = [torchmodel];\n","    else:\n","        for m in model:\n","            torchmodel=load_learner(model).model;\n","            if torch.cuda.is_available():\n","              torchmodel = torchmodel.to(\"cuda\");\n","            # torch.save(torchmodel.state_dict(),\"temp.pkl\");\n","            # torchmodel = torch.load(\"temp.pkl\");\n","            key.append(torchmodel);\n","    if not isinstance(outName,list):\n","        outName = [local_segmentation_output_masks/outName]\n","        output_dirs += outName;\n","    else:\n","        outName = [local_segmentation_output_masks/n for n in outName];\n","        output_dirs += outName;\n","    process_instructions.append((key,outName));\n","    \n","print(\"model loaded and instructions created\");\n","        "]},{"cell_type":"code","source":["process_instructions[0][0][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-rytNB8Epxa","executionInfo":{"status":"ok","timestamp":1675276395772,"user_tz":300,"elapsed":13,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"562e7f06-07c3-4a1f-c21e-32493f5625eb"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DynamicUnet(\n","  (layers): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): BasicBlock(\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (3): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (4): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (5): BasicBlock(\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (7): Sequential(\n","        (0): BasicBlock(\n","          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","        (2): BasicBlock(\n","          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","    )\n","    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Sequential(\n","      (0): ConvLayer(\n","        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (1): ConvLayer(\n","        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","    )\n","    (4): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (5): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (6): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (7): UnetBlock(\n","      (shuf): PixelShuffle_ICNR(\n","        (0): ConvLayer(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): PixelShuffle(upscale_factor=2)\n","      )\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): ConvLayer(\n","        (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (conv2): ConvLayer(\n","        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): ReLU()\n","      )\n","      (relu): ReLU()\n","    )\n","    (8): PixelShuffle_ICNR(\n","      (0): ConvLayer(\n","        (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n","        (1): ReLU()\n","      )\n","      (1): PixelShuffle(upscale_factor=2)\n","    )\n","    (9): ResizeToOrig()\n","    (10): MergeLayer()\n","    (11): ResBlock(\n","      (convpath): Sequential(\n","        (0): ConvLayer(\n","          (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (1): ReLU()\n","        )\n","        (1): ConvLayer(\n","          (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (idpath): Sequential()\n","      (act): ReLU(inplace=True)\n","    )\n","    (12): ConvLayer(\n","      (0): Conv2d(99, 32, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"guSkdEEN4gGB","tags":[]},"source":["### Do pre-segmentation file management\n","Create output folder, find which files are remaining to segment, chunk files into batches for segmentation and upload"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":179},"id":"ggQsVRM7Xq48","outputId":"d0f7f168-fea6-48bb-cbd3-c7eb0e177ac8","executionInfo":{"status":"ok","timestamp":1675276400427,"user_tz":300,"elapsed":4664,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["effective batchsize: 1\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='2' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [2/2 00:03&lt;00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["input files: 6347\n","output files: [0, 0]\n","remaining files: 6347\n"]}],"source":["if process_logging: logging.debug(\"preparing filepaths...\");\n","if not os.path.exists(local_segmentation_output_masks):\n","    os.makedirs(local_segmentation_output_masks,exist_ok=True);\n","for d in output_dirs:\n","    if not os.path.exists(d):\n","        os.makedirs(d,exist_ok=True);\n","        \n","model_batchsize = 32\n","## prepare files\n","\n","#as far as I can tell through testing, this only matters for ensuring RAM usage stays low\n","batchSize = 256;\n","if not external_splitting_stitching:\n","    batchSize = max(int(batchSize / (x_slices*y_slices) / model_batchsize)*model_batchsize,1);\n","print(\"effective batchsize:\",batchSize)\n","\n","\n","files = get_image_files_recursively(local_segmentation_images);\n","\n","partial_upload = False;\n","\n","#make destination folders to match input directory tree\n","for name in files:\n","    for d in output_dirs:\n","        os.makedirs(d/(Path(os.path.relpath(name,local_segmentation_images)).parent),exist_ok=True);\n","\n","completed_masks = [];\n","for d in progress_bar(output_dirs):\n","    cmasks = [os.path.relpath(x,d) for x in get_image_files_recursively(d)];\n","    if not persistent_files or True:\n","        c = !gsutil ls -r \"gs://{gcp_segmentation_output_masks/os.path.basename(d)}\"\n","        if any([x.startswith(\"CommandException\") for x in c]): c = [];\n","        # print(c)\n","        t = [os.path.relpath(x,f\"gs://{gcp_segmentation_output_masks/os.path.basename(d)}\") for x in c if x != '' and not x.endswith((':','.zip','.nd','.flag'))];\n","        # print(t);\n","        partial_upload = partial_upload or any([s for s in t if t not in cmasks]);\n","        cmasks += t;\n","    completed_masks.append(cmasks);\n","# print(completed_masks);\n","print(\"input files:\",len(files))\n","total_files = len(files);\n","print(\"output files:\",[len(set(cmasks)) for cmasks in completed_masks])\n","# print(\"output files:\",[cmasks for cmasks in completed_masks])\n","\n","files = [fi for fi in files if any([os.path.relpath(fi,local_segmentation_images) not in cmasks for cmasks in completed_masks])];\n","print(\"remaining files:\",len(files))\n","files_remaining = len(files);\n","\n","# print(batchSize);\n","fileChunks = list(chunked(files, chunk_sz=batchSize));\n","\n","filestate_read = True;\n"]},{"cell_type":"markdown","source":["## Segment Movie"],"metadata":{"id":"pHRC0uCgN-fP"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"bRLQw7lsSsXT","executionInfo":{"status":"ok","timestamp":1675276400428,"user_tz":300,"elapsed":8,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["if external_splitting_stitching:\n","    if process_logging: logging.debug(\"starting external_splitting segmentation...\");\n","    stitching_complete = False;\n","    if not filestate_read:\n","        raise Exception(\"Error: file output state not updated since last processing, please run the \\\"pre-segmentation file management\\\" cell again\")\n","    filestate_read = False\n","    cpus = len(os.sched_getaffinity(0))\n","    if files_remaining != 0:\n","        files_changed = True;\n","        p = progress_bar(fileChunks,files_remaining//batchSize+1); #makes a progress bar\n","        for n,chunk in enumerate(p):\n","            for models,out in process_instructions:\n","                outputs = [];\n","                for m in models:\n","                    res = m(chunk);\n","                    print(res);\n","                    raise Exception()\n","                    if torch.cuda.is_available():\n","                        dl = m.dls.test_dl(chunk,device=torch.device('cuda'));\n","                        dl.to('cuda');\n","                    else:\n","                        dl = m.dls.test_dl(chunk,num_workers=cpus);\n","                    _,_,dec_preds = m.get_preds(with_decoded=True,dl=dl);\n","                    outputs.append(dec_preds);\n","                if len(out) == len(outputs): #should also work for model splitting if can figure out how to make outputs the right shape\n","                    for p,put in zip(out,outputs):\n","                        for path,prediction in zip(chunk,put):\n","                            basename = os.path.relpath(path,local_segmentation_images); #preserve input directory structure\n","                            imsave(p/basename,prediction.numpy().astype('uint8'),check_contrast=False);\n","                else: #TODO: TEST AND FIX\n","                    print(\"ERROR: NOT IMPLEMENTED\");\n","            if process_logging: \n","                try:\n","                    time_remaining = format_time(p.pred_t - p.last_t + p.start_t);\n","                    logging.debug(f\"chunk {n} complete; time remaining: {time_remaining}\");\n","                except Exception as e:\n","                    logging.error(e);\n","                    logging.debug(f\"chunk {n} complete\");\n","                    \n","                \n","            if not persistent_files:\n","                with capture_output() as capture:\n","                    !gsutil -m rsync -r \"{local_segmentation_output_masks}\" \"gs://{gcp_segmentation_output_masks}\"\n","    if not stitching_complete:\n","        print(\"image segmentation process complete, finishing up...\");\n","        with open(local_segmentation_output_masks/'segmentation_complete.flag','w') as f:\n","            pass;\n","        #zip files if required\n","        if zip_output:\n","            if not persistent_files or (partial_upload and files_changed):\n","                #download external files\n","                !gsutil -m rsync -r \"gs://{gcp_segmentation_output_masks}\" \"{local_segmentation_output_masks}\"\n","            for folder in output_dirs:\n","                if files_changed or not os.path.exists(folder.with_suffix('.zip')):\n","                    with capture_output() as capture:\n","                        !(cd \"{folder.parent}\" && zip -r \"{folder.with_suffix('.zip').name}\" \"{folder.name}\")\n","                        !gsutil -m cp \"{folder.with_suffix('.zip')}\" \"gs://{gcp_segmentation_output_masks/folder.with_suffix('.zip').name}\"\n","        #this is actually insane. The GCP bucket has to have at least one file in the parent directory\n","        #or it just like forgets to put the innermost directory. I have no idea why, but this fixes it\n","        with open(\"foothold.txt\",'w') as f:\n","            pass;\n","        # with capture_output() as capture:\n","        #     !gsutil cp foothold.txt \"gs://{gcp_segmentation_output_masks.parent}/foothold.txt\"\n","        with capture_output() as capture:\n","            !gsutil -m rsync -r \"{local_segmentation_output_masks}\" \"gs://{gcp_segmentation_output_masks}\"\n","        print(\"folder processing complete\");\n","        stitching_complete = True;\n","        if process_logging: logging.debug(\"segmentation fully complete\");\n","        print(\"segmentation complete!\");\n","    else:\n","        print(\"segmentation already complete!\");\n","        stitching_complete = True;"]},{"cell_type":"code","execution_count":20,"metadata":{"tags":[],"colab":{"base_uri":"https://localhost:8080/","height":491},"id":"SJZrORFO649Y","executionInfo":{"status":"error","timestamp":1675276404321,"user_tz":300,"elapsed":3657,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}},"outputId":"84cfc502-0f29-42f3-a009-d206ab1ef83b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='0' class='' max='6348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      0.00% [0/6348 00:00&lt;?]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/tifffile/tifffile.py:2036: UserWarning: <tifffile.TiffWriter 'p_s2_t82.TIF'> writing zero-size array to nonconformant TIFF\n","  warnings.warn(\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-370bde592955>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#should also work for model splitting if can figure out how to make outputs the right shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0mnres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             \u001b[0;31m# We have to remove res.orig to avoid hanging refs and therefore memory leaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/fastai/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mact_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mact_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;31m# %% ../nbs/01_layers.ipynb 133\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 814.00 MiB (GPU 0; 14.76 GiB total capacity; 11.34 GiB already allocated; 335.88 MiB free; 13.40 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["if not external_splitting_stitching:\n","    if process_logging: logging.debug(\"starting nonexternal_splitting segmentation\");\n","    if not filestate_read and False:\n","        raise Exception(\"Error: file output state not updated since last processing, please run the \\\"pre-segmentation file management\\\" cell again\")\n","    filestate_read = False\n","    from IPython.utils.io import capture_output\n","    from multiprocessing import Pool\n","    cpus = len(os.sched_getaffinity(0))\n","    \n","    def split_image(name):\n","        try:\n","            im = imread(name);\n","        except:\n","            raise IOError(f\"Error while attempting to read image {name}\");\n","        if auto_rescale:\n","            im = rescale_intensity(im);\n","        assert isinstance(im,np.ndarray);\n","\n","        M = (im.shape[0]-context_bounds[0]-context_bounds[2]-crop[0]-crop[2])/y_slices;\n","        N = (im.shape[1]-context_bounds[1]-context_bounds[3]-crop[1]-crop[3])/x_slices;\n","\n","        if int(M) != M or int(N) != N:\n","            raise Exception(f\"ERROR: Mask with size {im.shape[:2]} cannot be sliced into {x_slices} columns and {y_slices} rows\\nwith context bounds of {context_bounds}; {M} and {N} not integers\");\n","        else:\n","            M = int(M)\n","            N = int(N)\n","            im = (im/256).astype('uint8');\n","            im = np.stack((im,im,im),axis=2);\n","            tiles = [im[y-context_bounds[0]:y+M+context_bounds[2],x-context_bounds[1]:x+N+context_bounds[3]] \n","                    for y in range(context_bounds[0]+crop[0],im.shape[0]-crop[0]-crop[2]-context_bounds[0]-context_bounds[2],M) \n","                    for x in range(context_bounds[1]+crop[1],im.shape[1]-crop[1]-crop[3]-context_bounds[1]-context_bounds[3],N)];\n","            return tiles;\n","    \n","    def stitch_image(tiles,outName):\n","        stitchMasks = []\n","        for i,m in enumerate(tiles):\n","            m = m.numpy().astype('uint8')\n","            y = i // x_slices;\n","            x = i % x_slices;\n","            imBounds = [crop[0]+context_bounds[0] if y != 0 else 0,m.shape[0]-crop[2]-context_bounds[2] if y != y_slices-1 else m.shape[0],crop[1]+context_bounds[1] if x != 0 else 0 ,m.shape[1]-crop[3]-context_bounds[3] if x != x_slices - 1 else m.shape[1]];\n","            stitchMasks.append(m[imBounds[0]:imBounds[1],imBounds[2]:imBounds[3]]);\n","        stitched = np.concatenate([np.concatenate(stitchMasks[i*x_slices:(i+1)*x_slices],axis=1) for i in range(y_slices)]);\n","        imsave(outName,stitched,check_contrast=False);\n","\n","    if files_remaining != 0:\n","        files_changed = True;\n","        stitching_complete = False;\n","        prog = progress_bar(fileChunks,files_remaining//batchSize+1); #makes a progress bar\n","        for n,chunk in enumerate(prog):\n","            basenames = [os.path.relpath(c,local_segmentation_images) for c in chunk]; #preserve input directory structure\n","            # print(basenames);\n","            with Pool(cpus) as p:\n","                chunk = Tensor(np.array([item for sublist in p.map(split_image,chunk) for item in sublist])).to('cuda' if torch.cuda.is_available() else \"cpu\").permute(0,3,1,2);\n","            for models,out in process_instructions:\n","                outputs = [];\n","                for m in models:\n","                    res = m(chunk);\n","                    outputs.append(res.to(\"cpu\").detach());\n","                if len(out) == len(outputs): #should also work for model splitting if can figure out how to make outputs the right shape\n","                    for path,put in zip(out,outputs):\n","                        grouped_preds = [put[i:i + x_slices*y_slices] for i in range(0, len(put), x_slices*y_slices)]\n","                        saveNames = [path/b for b in basenames];\n","                        with Pool(cpus) as p:\n","                            p.starmap(stitch_image,zip(grouped_preds,saveNames));\n","                else:\n","                    print(\"ERROR: NOT IMPLEMENTED\");\n","            if not persistent_files:\n","                with capture_output() as capture:\n","                    !gsutil -m rsync -r \"{local_segmentation_output_masks}\" \"gs://{gcp_segmentation_output_masks}\"\n","            if process_logging: \n","                try:\n","                    time_remaining = format_time(prog.pred_t - prog.last_t + prog.start_t);\n","                    logging.debug(f\"chunk {n} complete; time remaining: {time_remaining}\");\n","                except Exception as e:\n","                    logging.error(e);\n","                    logging.debug(f\"chunk {n} complete\");\n","    if not stitching_complete:\n","        print(\"image segmentation process complete, finishing up...\");\n","        with open(local_segmentation_output_masks/'segmentation_complete.flag','w') as f:\n","            pass;\n","        #zip files if required\n","        if zip_output:\n","            if not persistent_files or (partial_upload and files_changed):\n","                print(\"downloading remote files to zip...\");\n","                #download external files\n","                with capture_output() as capture:\n","                    !gsutil -m rsync -r \"gs://{gcp_segmentation_output_masks}\" \"{local_segmentation_output_masks}\"\n","            print(\"zipping files...\")\n","            for folder in progress_bar(output_dirs):\n","                if files_changed or not os.path.exists(folder.with_suffix('.zip')):\n","                    with capture_output() as capture:\n","                        !(cd \"{folder.parent}\" && zip -r \"{folder.with_suffix('.zip').name}\" \"{folder.name}\")\n","                        !gsutil -m cp \"{folder.with_suffix('.zip')}\" \"gs://{gcp_segmentation_output_masks/folder.with_suffix('.zip').name}\"\n","        print(\"copying files to remote...\");\n","        with capture_output() as capture:\n","            !gsutil -m rsync -r \"{local_segmentation_output_masks}\" \"gs://{gcp_segmentation_output_masks}\";\n","        stitching_complete = True;\n","        if process_logging: logging.debug(\"segmentation complete, awaiting integrity verification\");\n","        print(\"segmentation complete!\");\n","    else:\n","        print(\"segmentation already complete!\");\n","        stitching_complete = True;"]},{"cell_type":"markdown","source":["## Verify Segmentation Completion"],"metadata":{"id":"J-C-QI8pOENv"}},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"id":"oe-fy9s_649a","executionInfo":{"status":"aborted","timestamp":1675276404322,"user_tz":300,"elapsed":8,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["#verify destination file integrity\n","#NOTE that this only compares the *number* of input files to the *number* of output files;\n","#filename mishaps could break this, as could errors when uploading the input files themselves.\n","original_files = !gsutil ls -r \"gs://{gcp_segmentation_images}\"\n","original_files = [os.path.relpath(x,f\"gs://{gcp_segmentation_images}\") for x in original_files if x and not x.endswith(('.flag','.nd','.zip',':'))];\n","# print(original_files);\n","\n","#check output folder integrity\n","for d in progress_bar(output_dirs):\n","    c = !gsutil ls -r \"gs://{gcp_segmentation_output_masks/os.path.basename(d)}\"\n","    if c[0].startswith('CommandException'):\n","        c = [];\n","    c = [x for x in c if x and not x.endswith((':','.flag','.zip','.nd')) and os.path.relpath(x,f\"gs://{gcp_segmentation_output_masks/os.path.basename(d)}\") in original_files];\n","    if len(c) < total_files:\n","        stitching_complete = False;\n","        if process_logging: logging.error(f\"Error in segmentation or uploading: output dir {gcp_segmentation_output_masks/os.path.basename(d)} incomplete (expected {total_files} objects but got {len(c)}, please run file prep and segmentation cells again to ensure output integrity\");\n","        print(f\"Error in segmentation or uploading: output dir {gcp_segmentation_output_masks/os.path.basename(d)} incomplete (expected {total_files} objects but got {len(c)}, please run file prep and segmentation cells again to ensure output integrity\");\n","#check zip file integrity, if applicable\n","if zip_output:\n","    ziplist = !gsutil ls -r \"gs://{gcp_segmentation_output_masks}\"\n","    ziplist = [os.path.basename(x) for x in ziplist if x.endswith('.zip')];\n","    for d in output_dirs:\n","        if d.with_suffix('.zip').name not in ziplist:\n","            stitching_complete = False;\n","            if process_logging: logging.error(f\"Error in segmentation or uploading: output zip file {d.with_suffix('.zip').name} missing from output directory. Please run file prep and segmentation cells again to ensure output integrity\");\n","            print(f\"Error in segmentation or uploading: output zip file {d.with_suffix('.zip').name} missing from output directory. Please run file prep and segmentation cells again to ensure output integrity\")\n","if stitching_complete:\n","    if logging: logging.debug(\"Segmentation successful! Output file integrity verified.\");\n","    print(\"Segmentation successful! Output file integrity verified.\")\n","else:\n","    print(\"Error: segmentation was not complete. Please run file prep and segmentation cells again to ensure output integrity\");"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J14-ixX9649b","executionInfo":{"status":"aborted","timestamp":1675276404323,"user_tz":300,"elapsed":8,"user":{"displayName":"Harrison Truscott","userId":"14976770828222387752"}}},"outputs":[],"source":["if stitching_complete:\n","    cleardir(GCP_transfer_folder)"]}],"metadata":{"colab":{"collapsed_sections":["MvFx9gc8x_t8","fhr4J0p_fJnl","7KnHRFG2PORL","g3XGCr8QNsKV"],"provenance":[]},"environment":{"kernel":"python3","name":"pytorch-gpu.1-10.m89","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-10:m89"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}